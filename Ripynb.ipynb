{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (1166566587.py, line 31)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[3], line 31\u001b[0;36m\u001b[0m\n\u001b[0;31m    master_df <- master_df %>%\u001b[0m\n\u001b[0m                            ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "#creating master csv\n",
    "library(tidyverse)\n",
    "library(dplyr)\n",
    "library(tidytext)\n",
    "library(stringr)\n",
    "library(readtext)\n",
    "library(lubridate)\n",
    "library(purrr)\n",
    "library(readxl)\n",
    "library(ggplot2)\n",
    "library(quanteda)\n",
    "library(jiebaR)\n",
    "library(readtext)\n",
    "library(pdftools)\n",
    "library(lubridate)\n",
    "library(purrr)\n",
    "library(wordcloud2)\n",
    "setwd(\"/Users/jasperhewitt/Desktop/github_repos/Campaigning_101/data\")\n",
    "\n",
    "\n",
    "\n",
    "#___________#__________### 1: CREATING MASTER FILE ####___________#__________# \n",
    "\n",
    "#import full crowdtangle csv 8073 rows\n",
    "master_df <- read.csv(\"/Users/jasperhewitt/Desktop/github_repos/Campaigning_101/data/all_attacks.csv\")\n",
    "\n",
    "#import xlsx with additional data for each candidate (party, city, english name, etc.)\n",
    "#candidate_info <- read_xlsx(\"/Users/jasperhewitt/Desktop/fertnews/candidates_info.xlsx\")\n",
    "\n",
    "#only keep relevant columns \n",
    "master_df <- master_df %>%\n",
    "  select('serial_number', 'User.Name', 'combined_text', 'attack', 'target')\n",
    "\n",
    "#filter so User.Name == houyuih\n",
    "master_df <- master_df %>%\n",
    "  filter(User.Name == 'houyuih')\n",
    "\n",
    "\n",
    "#in the combined_text column, only keep the sentences that contain the target. these are the interpunction that may be used\n",
    "# 。 ？ ！ \n",
    "\n",
    "#search pattern 侯友宜 critcize 民進黨\n",
    "#search_pattern <- \"民進黨|民主進步黨|賴|蔡|綠營|蕭\"\n",
    "\n",
    "\n",
    "#search_pattern <- \"民進黨|民主進步黨|賴|蔡|綠營|蕭\"\n",
    "search_pattern <- \"民眾黨|柯|藍白\"\n",
    "master_df <- master_df %>%\n",
    "  mutate(important_sentences = str_split(combined_text, \"[。？！]\")) %>% #split it into sentences\n",
    "  #find the sentences that contain some of our keywords, and paste that sentences into the important_sentences column\n",
    "  mutate(important_sentences = map(important_sentences, ~ .[str_detect(., regex(search_pattern, ignore_case = TRUE))])) %>%\n",
    "  #unnest the columns, so each important sentence will get their own row. just like 'explode in pandas' \n",
    "  unnest(important_sentences)%>%\n",
    "  distinct() %>%\n",
    "  # Filter rows where 'target' contains one of the terms in the search pattern\n",
    "  filter(str_detect(target, regex(search_pattern, ignore_case = TRUE)))\n",
    "\n",
    "\n",
    "unique_serial_numbers <- length(unique(master_df$serial_number))\n",
    "cat(\"Number of unique serial numbers:\", unique_serial_numbers, \"\\n\")\n",
    "\n",
    "\n",
    "#show len master_df\n",
    "nrow(master_df)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#___________#__________### 7:  WORDCLOUD FOR CANDIDATES FERTILITY POSTS ####___________#__________# \n",
    "\n",
    "\n",
    "#___________# TOKENIZATION, STOPWORDS, CUSTOM DICTIONARY #__________# \n",
    "\n",
    "#this part is based on this tutorial by NTNU: https://alvinntnu.github.io/NTNU_ENC2036_LECTURES/chinese-text-processing.html\n",
    "\n",
    "#custom dict and stopwords: https://github.com/Jasper-Hewitt/elec_fertility/tree/main/data/dict_and_stopwords\n",
    "\n",
    "master_fert_df <- master_df\n",
    "\n",
    "#add doc_id\n",
    "master_fert_df <- master_fert_df %>% \n",
    "  mutate(doc_id = row_number())\n",
    "\n",
    "#load stopwords \n",
    "stopwords <- readLines(\"stopwords_zh_trad.txt\",\n",
    "                       encoding = \"UTF-8\")\n",
    "\n",
    "#check len of stopwrods\n",
    "length(stopwords)\n",
    "\n",
    "#load custom dictionary \n",
    "my_seg <- worker(bylines = T,\n",
    "                 user = \"customdict.txt\",\n",
    "                 symbol = T)\n",
    "\n",
    "\n",
    "## word tokenization\n",
    "master_fert_word <- master_fert_df %>%\n",
    "  unnest_tokens(\n",
    "    output = word,\n",
    "    input = important_sentences,  # the name of the column we are plotting\n",
    "    token = function(x)\n",
    "      segment(x, jiebar = my_seg)\n",
    "  ) %>%\n",
    "  group_by(doc_id) %>%\n",
    "  mutate(word_id = row_number()) %>% # create word index within each document\n",
    "  ungroup\n",
    "\n",
    "\n",
    "\n",
    "custom_stopwords <- c(\"政黨輪替\", \"表達\", \"請問\", \"藍白\", \"藍白\", \"柯文哲\", \"民眾黨\",\"參選人\", \"參選\",\"無法\", \"目標\", \"力量\",\"不斷\", \"完全\", \"實現\", \"希望\", '政策', '立委', '改變', '支持', '告訴', '願意', '推動', '承諾', '這片', '再次', '最大', '中央', '重要', '到底', '建設','期待', \n",
    "                      '帶給', '趙少康', '選舉', '立刻', '必須', '清德', '清楚', '卻是', '主張', \n",
    "                      '變成', '絕對', '區域', '侯友', '選擇', '更是', '主席', '不能', '確是', '還給',  \n",
    "                      \"執政\", \"總統\", \"國民黨\", \"2024\", \"政治\", \"如今\", \"在此\", '最後', '全國', \"賴清德\", \"中華民國\", \"宜來\", \"未來\", \"侯友宜\", \"一定\", \"民眾\", \"就讓\",\n",
    "                      \"民進黨\", \"人民\", \"政府\", \"國家\", \"報導\", \"可能\", \"指出\", \"認為\", \"新聞網\", \"國際\", \n",
    "                      \"應該\", \"可能\", \"提出\", \"過去\", \"現在\", \"進行\",\"今天\", \"相關\", \"社會\",\n",
    "                      \"議題\", \"很多\", \"undo\", \"需要\", \"需求\", \"已經\", \"目前\", \"今年\", \"透過\",\n",
    "                      \"地方\", \"沒有\", \"記者\", \"成為\", \"持續\", \"市場\", \"表示\", \"台灣\", \"造成\",\n",
    "                      \"不少\", \"原因\", \"影響\", \"問題\", \"/\", \"10\", \"20\", \"30\", \"一起\", \"市長\", \"市民\", \"朋友\",\n",
    "                      \"城市\", \"12\", \"11\", \"https\")  # specific words about 生育率# specific words about 生育率\n",
    "stopwords <- c(stopwords, custom_stopwords)\n",
    "\n",
    "stopwords\n",
    "length(stopwords)\n",
    "\n",
    "#___________# WORDCLOUD AND WORD FREQUENCY LIST #__________# \n",
    "\n",
    "## create word freq list\n",
    "master_word_freq <- master_fert_word %>%\n",
    "  mutate(word = str_trim(word)) %>%  # remove whitespaces\n",
    "  filter(str_length(word) > 1, !word %in% stopwords) %>% # remove single character words and stopwords \n",
    "  count(word) %>%\n",
    "  arrange(desc(n))\n",
    "\n",
    "\n",
    "#plot wordcloud\n",
    "master_word_freq %>%\n",
    "  filter(n > 3) %>%\n",
    "  filter(nchar(word) >= 2) %>% ## remove one character words because they are usually not really relevant\n",
    "  wordcloud2(shape = \"circle\", size = 0.6)\n",
    "#save wordcloud as image\n",
    "# wordcloud2(shape = \"circle\", size = 0.4) %>% \n",
    "#   saveWidget(\"wordcloud_fertility.html\", selfcontained = F)\n",
    "\n",
    "# Select 20 most frequent words\n",
    "top_20_words <- master_word_freq %>%\n",
    "  top_n(20, n)\n",
    "\n",
    "# plot sideways word frequency list\n",
    "ggplot(top_20_words, aes(x = reorder(word, n), y = n)) + \n",
    "  geom_bar(stat = \"identity\", fill = \"skyblue\") +\n",
    "  coord_flip() +\n",
    "  labs(x = \"Words\", y = \"Count\", title = \"20 most frequent words in candidates' \\n posts about fertility\") +\n",
    "  theme_minimal() +\n",
    "  theme(text = element_text(family = \"Songti SC\", size = 20))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
